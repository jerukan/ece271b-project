{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import lightning as L\n",
    "import numpy as np\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "import torch\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import Dataset, random_split\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharDataset(Dataset):\n",
    "    \"\"\"\n",
    "    General dataset for single character data loading.\n",
    "\n",
    "    Assumes that in the directory given, the subdirectories are the classes.\n",
    "    These directory names should be the single character class.\n",
    "    \"\"\"\n",
    "    def __init__(self, img_dir, transform=None):\n",
    "        self.img_dir = Path(img_dir)\n",
    "        if not self.img_dir.exists():\n",
    "            raise FileNotFoundError(f\"{img_dir} does not exist\")\n",
    "        alldirs = [p for p in self.img_dir.glob(\"*\") if p.is_dir()]\n",
    "        self.imgpaths = []\n",
    "        self.imglabels = []\n",
    "        for d in alldirs:\n",
    "            chclass = d.stem.lower()\n",
    "            imgpaths_dirty = list(d.glob(\"*.jpg\")) + list(d.glob(\"*.png\"))\n",
    "            imgpaths = []\n",
    "            for i in range(len(imgpaths_dirty)):\n",
    "                try:\n",
    "                    Image.open(imgpaths_dirty[i])\n",
    "                except UnidentifiedImageError:\n",
    "                    print(f\"Image {imgpaths_dirty[i]} is not a valid image, skipping\")\n",
    "                    continue\n",
    "                imgpaths.append(imgpaths_dirty[i])\n",
    "            self.imgpaths.extend(imgpaths)\n",
    "            self.imglabels.extend([chclass] * len(imgpaths))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imglabels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        imgpath = self.imgpaths[idx]\n",
    "        img = Image.open(imgpath).convert(\"L\")\n",
    "        label = self.imglabels[idx]\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "    \n",
    "\n",
    "def ds_to_vectors(ds, size=28):\n",
    "    imgs = np.array([np.array(x[0].resize((28, 28))).reshape(-1) for x in ds])\n",
    "    labs = np.array([x[1] for x in ds])\n",
    "    return imgs, labs\n",
    "\n",
    "\n",
    "def create_knn(ds, k=5, size=28):\n",
    "    imgs, labs = ds_to_vectors(ds, size=size)\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(imgs, labs)\n",
    "    return knn\n",
    "\n",
    "\n",
    "def run_test_knn(ds, knn, size=28):\n",
    "    imgs, labs = ds_to_vectors(ds, size=size)\n",
    "    preds = knn.predict(imgs)\n",
    "    return labs, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomrot_T = v2.Compose([\n",
    "    v2.PILToTensor(),\n",
    "    v2.RandomRotation(179),\n",
    "    v2.ToPILImage()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handiso_ds_train = CharDataset(\"data/handwritten-isolated-english/train\")\n",
    "handiso_ds_test = CharDataset(\"data/handwritten-isolated-english/test\")\n",
    "notmnist_ds = CharDataset(\"data/notMNIST_small\")\n",
    "notmnist_ds_train, notmnist_ds_test = random_split(notmnist_ds, [0.8, 0.2])\n",
    "stdocr_ds_train = CharDataset(\"data/standard_ocr_dataset/data/training_data\") + CharDataset(\"data/standard_ocr_dataset/data2/training_data\")\n",
    "stdocr_ds_test = CharDataset(\"data/standard_ocr_dataset/data/testing_data\") + CharDataset(\"data/standard_ocr_dataset/data2/testing_data\")\n",
    "mnist_ds_train = MNIST(Path(os.getcwd(), \"data\"), train=True)\n",
    "mnist_ds_test = MNIST(Path(os.getcwd(), \"data\"), train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"handwritten-isolated-english sizes: [train:{len(handiso_ds_train)}, test:{len(handiso_ds_test)}]\")\n",
    "print(f\"not MNIST sizes: [train:{len(notmnist_ds_train)}, test:{len(notmnist_ds_test)}]\")\n",
    "print(f\"standard OCR ds sizes: [train:{len(stdocr_ds_train)}, test:{len(stdocr_ds_test)}]\")\n",
    "print(f\"MNIST sizes: [train:{len(mnist_ds_train)}, test:{len(mnist_ds_test)}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handwrknn = create_knn(handiso_ds_train, k=5, size=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handwr_test_data, handwr_test_lab = ds_to_vectors(handiso_ds_test, size=28)\n",
    "handwr_test_labpred = handwrknn.predict(handwr_test_data)\n",
    "handwrknn.score(handwr_test_data, handwr_test_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notmnistknn = create_knn(notmnist_ds_train, k=5, size=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notmnist_test_data, notmnist_test_lab = ds_to_vectors(notmnist_ds_test, size=28)\n",
    "notmnist_test_labpred = notmnistknn.predict(notmnist_test_data)\n",
    "notmnistknn.score(notmnist_test_data, notmnist_test_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(notmnist_test_lab, notmnist_test_labpred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdocrknn = create_knn(stdocr_ds_train, k=5, size=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdocr_test_data, stdocr_test_lab = ds_to_vectors(stdocr_ds_test, size=28)\n",
    "stdocr_test_labpred = stdocrknn.predict(stdocr_test_data)\n",
    "stdocrknn.score(stdocr_test_data, stdocr_test_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(stdocr_test_lab, stdocr_test_labpred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnistknn = create_knn(mnist_ds_train, k=5, size=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_test_data, mnist_test_lab = ds_to_vectors(mnist_ds_test, size=28)\n",
    "mnist_test_labpred = mnistknn.predict(mnist_test_data)\n",
    "mnistknn.score(mnist_test_data, mnist_test_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ece271bpr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
